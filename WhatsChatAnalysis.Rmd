---
title: "SentimentAnalysis"
author: "Vinaygam"
date: "December 21, 2017"
output: html_document
description: "Sentiment Analysis"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

Format improvement from R analyisis https://github.com/lohithpro/whatsapp_chat-analysis/blob/master/whatsappchatanalysis.R

## Steps

1) Load library 
2) Set working directory patth
3) Load whatsapp text data
4) Extract Only Message column
5) Clean not required Text
6) Get frequency of word
7) Display bar graph

```{r Load library}
#install.packages("readtext")
require(readtext)
#install.packages(c("stringr", "zoo", "ggplot2", "scales", "dplyr"))

library("stringr")

library("zoo")

library("ggplot2")

library("dplyr")

library("scales")
setwd("DIR_PATH")
all_data <- readLines("WhatsApp Chat.txt")
head(all_data)
#convert to utf-8 encoding  and remove unrecognised
all_data <- iconv(all_data, "UTF-8", "ASCII", sub = "")

head(all_data)
```


Data Wrangling and Cleaning

```{r}
#========================================================

# Data Wrangling and Cleaning

#========================================================



#Removing the first message


all_data = all_data[-1]
head(all_data)
```

Extracting date and time 

```{r}
#Extracting date and time  

# %I hours as decimals,%M minute, 

date_time <- format(strptime(all_data, "%d/%m/%Y, %H:%M"), "%d/%m/%Y, %H:%M")



#Extracting date

date = gsub(",.*$","",date_time) #Fetching all before ","



#Extracting time

time = gsub("^.*,","",date_time) #Fetching all after ","

time = str_trim(time) #Removing spaces from both ends
date
time 



sender <- 'sender' #Temorary Data

message <- all_data
```

Creating Data Frame

```{r}
#Creating Data Frame

clean_data = data.frame(date,time,sender,message)

head(clean_data)

```

Extracting sender and message from the data frame


```{r}
#Extracting sender and message from the data frame

#Fetching only complete cases

sender_message = clean_data[complete.cases(clean_data),4] 

sender_message = gsub("^.*?-","",sender_message)

sender_message = str_trim(sender_message) 



#Extracting message

message = gsub("^.*?:","",sender_message) 

message = str_trim(message) #Removing spaces from both ends

head(message)

#Updating the data frame with new message data

clean_data$message <- as.character(clean_data$message)

clean_data[complete.cases(clean_data),4] <- message



#Extracting sender names

sender = gsub("?:.*$","",sender_message) 

# Removing prefixes and other names from sender "Customized"

sender = gsub("NED?.*$","",sender)

sender = str_trim(sender) #Removing spaces from both ends

head(sender) 
```
Updating the data frame with new sender data

```{r}
#Updating the data frame with new sender data

clean_data$sender <- as.character(clean_data$sender)

clean_data[complete.cases(clean_data),3] <- sender



#Replacing remaining "sender" values with NA

clean_data[clean_data=="sender"]<- NA
clean_data
```

Using transform function from Zoo Package

```{r}
#Using transform function from Zoo Package 

#Filling NA with previous values

#Detailed explanation > www.tensorflowhub.org

clean_data <- transform(clean_data, date = na.locf(date), time = na.locf(time),
                        
                        sender = na.locf(sender))





#This is a custom function, 

#Use only if you want to remove unknown contacts

clean_data = subset(clean_data, !grepl("92 334", sender))

nrow(clean_data)



#Refactorizing 

clean_data$sender <- as.factor(clean_data$sender)





#Exploring Data

summary(clean_data)

nrow(clean_data)



summary(clean_data$sender,maxsum = 25)
```
Feature Engineering

```{r}
#========================================================

# Feature Engineering

#========================================================

#Setting media messages to empty space for length 0

clean_data[clean_data=="<Media omitted>"]<-""

#Finding length of each message

clean_data$message_length <- nchar(clean_data$message)

#Restting media messages 

clean_data[clean_data==""]<-"<Media omitted>"

summary(clean_data$message_length)

length(clean_data[clean_data=="<Media omitted>"])
```

Data Visualization


```{r}
#========================================================

# Data Visualization

#========================================================

#===== Plot 1 =====#

q <- ggplot(clean_data, aes(sender))+
  
  geom_bar()+
  
  ylab("number of messages")
q + theme(axis.text.x=element_text(angle=45, hjust=1))
```
Plot 2 


```{r}
#===== Plot 2 =====#

q <- ggplot(clean_data, aes(sender,message_length))+
  
  geom_bar(stat="identity")+
  
  ylab("sum of message length")
q + theme(axis.text.x=element_text(angle=45, hjust=1))

```

Plot 3

```{r}
#===== Plot 3 =====#

#Mean of the length of each message for each sender

grouped_mean_length <- aggregate(message_length ~ sender, clean_data, mean)

grouped_mean_length

q<- ggplot(grouped_mean_length, aes(sender,message_length))+
  
  geom_bar(stat="identity")+
  
  ylab("mean of message length")
q + theme(axis.text.x=element_text(angle=45, hjust=1))
```

Plot 4

```{r}
#===== Plot 4 =====#

#No of records across date

date_count<-data.frame(table(clean_data$date))
# clean_data$date
colnames(date_count) <- c("date", "count")
# date_count
# 
# 
# #Scatter plot for the number of messages per given date
# 
# ggplot(date_count, aes(as.Date(date, '%Y-%m-%d'),count))+
# 
# geom_line()
# 
#  # scale_x_date(breaks = date_breaks("1 months"),labels = date_format("%m/%y"))+
# 
# #  xlab("date")+
# 
#   #ylab("number of messages")

```

Plot 5

```{r}
#===== Plot 5 =====#

#No of records across date and sender

date_sender_count<-data.frame(table(clean_data$sender,clean_data$date))

colnames(date_sender_count) <- c("sender","date", "count")



#Scatter plot for the number of messages for each sender per given date

ggplot(date_sender_count, aes(as.Date(date, "%d/%m/%Y"), count, color=sender))+
  
  geom_line()+
  
  scale_x_date(breaks = date_breaks("1 months"),labels = date_format("%m/%y"))+
  
  xlab("date")+
  
  ylab("number of messages")
```

